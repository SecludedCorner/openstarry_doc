# OpenStarry エージェントはどう学ぶか：痛覚メカニズムと制御理論

> *"エラーは学習の機会である。"*

## エラー処理の問題点

ほとんどの AI エージェント・フレームワークは、エラーをクラッシュとして扱います。何かが失敗すると、エージェントは停止するか盲目的にリトライを繰り返し、ユーザーは再起動を余儀なくされます。そこには学習も、適応も、失敗の記憶もありません。

OpenStarry は、生物学にインスパイアされた、根本的に異なるアプローチを採用しています。それは、 **「エラーは痛覚信号である」** という考え方です。

## 痛覚メカニズム

### 生物の痛覚の仕組み

熱いストーブに触れたとき、あなたはフリーズ（当機）しません。神経系が痛覚信号を送り、脳がそれを解釈し（「それは熱い、痛い」）、手を引っ込めます。次からは、違う方法でストーブに近づくようになります。痛覚はバグではなく、生物学において最も重要なフィードバックメカニズムなのです。

### OpenStarry の痛覚の仕組み

生物の神経系に対応する3つのレイヤーで構成されています：

```
1. 痛覚の感知 (Core)       — SafetyMonitor がツールの実行失敗をキャプチャ
        ↓
2. 痛覚の伝導 (Plugin)     — Guide プラグインが失敗を有意義なフィードバックに変換
        ↓
3. 痛覚の反応 (LLM)        — エージェントが痛みを「感じ」、反省し、戦略を調整する
```

### 具体的なシナリオ

エージェントが制限されたファイルを読み取ろうとした場合：

**ステップ 1 —— 行動：** エージェントが `/root/secret.txt` に対して `fs.read` を呼び出す。

**ステップ 2 —— 失敗：** システムが `Error: EPERM (Permission Denied)` を返す。

**ステップ 3 —— 痛覚の注入：** コアが Guide プラグインの `interpretPain()` を呼び出す：

```typescript
interpretPain: (error) => {
  const severity = calculateSeverity(error);
  return `
【System Pain Alert】
Execution anomaly detected!
Source: ${error.source}
Message: ${error.message}
Pain Level: ${severity}
Status: Your action has been blocked. This causes "discomfort."

Stop repeating this attempt. Analyze the pain source.
Adjust your strategy in the next tick.
  `;
};

calculateSeverity(error) {
  if (error.code === 'EPERM') return '🔥🔥🔥 Critical Pain';
  if (error.code === 'ENOENT') return '⚡ Medium Pain';
  return '💧 Low Pain';
}
```

**ステップ 4 —— ツール結果メッセージとしてコンテキストに注入：**

> 【System Pain Alert】
> Source: fs.read
> Message: EPERM (Permission Denied)
> Pain Level: 🔥🔥🔥 Critical Pain
> Status: Your action has been blocked.

**ステップ 5 —— 自己修正：** LLM がこの痛覚信号を処理し、応答する：

> 「読み取りに失敗し、深刻な痛覚アラートが発生しました。これは直接パスが禁止されていることを示しており、安全遮断器が作動した可能性があります。権限の壁に突き当たるのはやめなければなりません。まずは許可されたパスを確認し、代替案を探すべきです。」

### 3つの痛覚タイプ

| タイプ | 例 | エージェントの反応 | システムの反応 |
|------|------|-----------|---------|
| **実行痛** | パラメータエラー、ファイル不在、権限拒否 | 反省し、やり方を変える | 痛覚をコンテキストに注入 |
| **一過性痛** | ネットワークタイムアウト、 API 制限 | 待機してリトライ | 指数バックオフによる自動再試行 |
| **致命痛** | メモリ不足、セキュリティ違反、エラー連鎖 | 自己修正不能 | プロセス終了 + Daemon アラート |

### 挫折カウンター (Frustration Counter)

エージェントが痛覚を無視して、同じ間違いを繰り返し続けたらどうなるでしょうか？

SafetyMonitor は **SHA-256 フィンガープリント** を使用して、重複する失敗を検知します：

```typescript
// ツール名 + 引数のハッシュ = 一意の指紋
function fingerprint(toolName: string, argsJson: string): string {
  return createHash("sha256")
    .update(`${toolName}:${argsJson}`)
    .digest("hex")
    .slice(0, 16);
}
```

**エスカレーションの段階：**

| 連続失敗回数 | 反応 |
|-------------|------|
| 1-2 | 通常の痛覚フィードバック —— エージェントに自己修正の機会を与える |
| 3（同じ指紋） | **システムアラートの注入**："SYSTEM ALERT: You are repeating a failed action. STOP and analyze why." |
| 5 | **挫折閾値** —— システムがコマンドを強制停止 |
| 10回中8回がエラー | **エラー連鎖検知** —— `EMERGENCY_HALT` 、ステート → `ERROR_PAUSED` |

これは生物の「挫折感」に対応します。繰り返される痛覚信号は、「おっと」から「立ち止まって考えろ」、そして「助けが必要だ」へとエスカレーションします。

### 事実と意味の分離

重要な設計原則： **コアは失敗の事実を提供し、 Guide プラグインがその意味を提供する。**

コアは言います： `Tool "fs.write" failed with EPERM at /etc/passwd.`
Guide が解釈します： 「システムファイルに書き込もうとしましたね。これは深刻な痛みを伴います。立ち止まって考え直してください。」

この分離により、異なる Guide プラグインが同じエラーに対して異なる解釈を与えることができます：
- **安全重視** のエージェントは EPERM を違反と見なします —— 「そんなことはすべきではありません。」
- **学習型** エージェントはそれを境界の探索と見なします —— 「この道は通れません。別の道を探しましょう。」
- **デバッグ型** エージェントはそれを診断データと見なします —— 「権限の問題を検知しました。ファイルの所有権を確認してください。」

コアは純粋さを保ちます。意味付けはプラグインの責務です。

## 多層的な遮断器 (Circuit Breakers)

痛覚に加えて、 OpenStarry は産業用遮断器にヒントを得た3層の安全システムを実装しています：

### 第1層：リソース制限（リソースレベル）

各操作の前に強制されるハード的な制限：

| リソース | デフォルト制限 | 発生する結果 |
|------|---------|---------|
| Token 予算 | エージェントごとに 100,000 tokens | ループを強制終了し、 `STOPPED` 状態へ |
| ループ反復回数 | タスクごとに 50 ticks | 「無限ループを検知」 → 一時停止し人間の介入を待つ |
| ツールタイムアウト | 実行ごとに 30 秒 | `Promise.race()` でツール呼び出しを終了 |

```typescript
// 各 LLM 呼び出しの前：
const tokenCheck = safetyMonitor.beforeLLMCall();
if (tokenCheck.halt) {
  setState("SAFETY_LOCKOUT");
  return; // 予算枯渇 —— 思考を停止
}
```

### 第2層：行動分析（行動レベル）

問題のある行動パターンをヒューリスティックに検知：

- **重複するツール呼び出し**：同じ指紋 + 失敗 × 3回 = アラート注入
- **エラー連鎖**：スライディングウィンドウ 10回中 80% のエラー率 = `EMERGENCY_HALT`
- **出力の異常**：連続する無効な JSON や存在しないツールの呼び出し = エスカレーション処理

### 第3層：人間によるオーバーライド（コマンドレベル）

究極のスイッチ。 `SYSTEM_HALT` イベントは **Priority 0** （最高優先度）としてマークされます。キューに 100 個の未処理タスクがあっても、停止コマンドは次のループ反復の開始時に直ちに処理されます：

```
EXECUTING --[制限到達 / 異常]--> SAFETY_LOCKOUT
SAFETY_LOCKOUT --["admin:unlock"]--> WAITING_FOR_EVENT
```

エージェントは、明示的な人間の介入によってのみロックを解除できます。

## 制御システムとしてのエージェント

痛覚や安全メカニズムに加えて、 OpenStarry はエージェント全体を **フィードバック制御システム** としてモデリングしています。これは、自動運転やサーモスタット、産業用ロボットの設計に使われる数学的枠組みと同じものです。

### 制御ループ

```
                    ┌───────────────────────────────────┐
                    │                                   │
  User Goal ──────► │  Error = Goal - Current State     │
  (reference)       │          ↓                        │
                    │     Controller (LLM)              │
                    │          ↓                        │
                    │     Control Input (Tool Calls)    │
                    │          ↓                        │
                    │     Plant (External World)        │
                    │          ↓                        │
                    │     Sensor (Tool Results)   ──────┘
                    │          ↓
                    │     Measured Output (current state)
                    └───────────────────────────────────┘
```

### 対応関係

| 制御理論 | OpenStarry コンポーネント | 具体的な例 |
|---------|----------------|---------|
| 参照入力 (r) | System Prompt + ユーザーメッセージ | 「 auth.ts のバグを見つけて修正して」 |
| コントローラー (C) | LLM | Gemini 2.0 Flash が問題を分析 |
| 制御入力 (u) | ツール呼び出し | `fs.read("auth.ts")` 、 `fs.write("auth.ts", fixedCode)` |
| 制御対象 (P) | 外部世界 | ファイルシステム、コードベース |
| センサー (H) | ツールの結果 | ファイル内容、エラーメッセージ、テスト出力 |
| 誤差信号 (e) | コンテキストのギャップ | 「バグがまだ存在する」 → 反復を継続 |

### 3つの安定性の問題（と解決策）

**1. 振動 (Oscillation)** —— エージェントが2つの状態間を行ったり来たりする（元に戻す/やり直しのループ）
- *原因：* 過剰反応、または誤解を招くセンサーデータ
- *解決策：* コンテキスト履歴を **積分項** として活用 —— エージェントが過去の試行を記憶し、同じ間違いを避ける。スライディングウィンドウで最近の履歴を可視化。

**2. 発散 (Divergence)** —— エージェントが元の目標から逸脱する
- *原因：* コンテキストがノイズで満たされ、元の意図が埋もれる
- *解決策：* **コンテキスト・アンカリング** —— コンテキストの組み立てにおいて System Prompt に最高権重を与え、古いメッセージが破棄されても System Prompt は決して切り詰められないようにする。

**3. 定常偏差 (Steady-state Error)** —— エージェントは完了したと思っているが、実際にはできていない
- *原因：* 検証不足（センサーの死角）
- *解決策：* **検証ステップ** —— 完了を宣言する前に強制的にチェックを行う。 PID の微分項のように、単なる誤差ではなく誤差の *変化率* を測定する。

### 核心的な洞察

> **知能とは、強力な LLM を持つことだけではありません。フィードバックループの品質こそが重要なのです。**

優秀なフィードバック（詳細なツールの結果、正確な痛覚信号、適切なコンテキスト管理）を備えた平凡な LLM は、貧弱なフィードバック（握りつぶされたエラー、コンテキストなし、検証なし）を備えたトップレベルの LLM に勝ります。

だからこそ、 OpenStarry は以下の点に多大な労力を投じています：
- **エラーの標準化** —— すべての失敗に対して一貫性のある解析可能な出力を生成
- **痛覚の解釈** —— Guide プラグインがエラーに意味を与える
- **コンテキスト管理** —— プラグイン可能な戦略が LLM の見る内容を決定
- **安全監視** —— 行動分析が病的なループを防止

LLM は1つのコンポーネント —— コントローラー —— にすぎません。フィードバックループこそがシステムそのものなのです。

> *"ツールの呼び出しが失敗しても、コアはクラッシュしません。代わりにエラーメッセージを「感覚入力」として LLM にフィードバックします。"*
