# OpenStarry エージェントの学習方法：痛覚メカニズムと制御理論

> *「エラーは学習の機会である。」*

## エラーハンドリングの問題点

多くの AI エージェントフレームワークは、エラーをクラッシュとして扱います。何かが失敗するとエージェントは停止するか、盲目的にリトライし、ユーザーが再起動します。そこには学習も、適応も、何が失敗したかの記憶もありません。

OpenStarry は生物学に着想を得た根本的に異なるアプローチを採用しています：**エラーは痛覚信号です**。

## 痛覚メカニズム（痛覚機制）

### 生物の痛覚はどう機能するか

熱いストーブに触れたとき、あなたはクラッシュしません。神経系が痛覚信号を送り、脳がそれを解釈し（「熱い、痛い」）、手を引っ込めます。次回、あなたはストーブに対して異なるアプローチを取ります。痛みはバグではありません — 生物学における最も重要なフィードバックメカニズムです。

### OpenStarry の痛覚はどう機能するか

生物の神経系を模した三層構造：

```
1. 痛覚感知 (Core)        — SafetyMonitor がツール実行の失敗をキャプチャ
        ↓
2. 痛覚伝導 (Plugin)      — Guide プラグインが失敗を意味のあるフィードバックに変換
        ↓
3. 痛覚反応 (LLM)         — エージェントが痛みを「感じ」、反省し、戦略を修正
```

### 具体的なシナリオ

エージェントが制限されたファイルを読もうとします：

**ステップ 1 — 行動:** エージェントが `/root/secret.txt` に対して `fs.read` を呼び出す

**ステップ 2 — 失敗:** システムが `Error: EPERM (Permission Denied)` を返す

**ステップ 3 — 痛覚の注入:** Core が Guide プラグインの `interpretPain()` を呼び出す：

```typescript
interpretPain: (error) => {
  const severity = calculateSeverity(error);
  return `
【System Pain Alert】
Execution anomaly detected!
Source: ${error.source}
Message: ${error.message}
Pain Level: ${severity}
Status: Your action has been blocked. This causes "discomfort."

Stop repeating this attempt. Analyze the pain source.
Adjust your strategy in the next tick.
  `;
};

calculateSeverity(error) {
  if (error.code === 'EPERM') return '🔥🔥🔥 Critical Pain';
  if (error.code === 'ENOENT') return '⚡ Medium Pain';
  return '💧 Low Pain';
}
```

**ステップ 4 — ツール結果メッセージとしてコンテキストに注入：**

> 【System Pain Alert】
> Source: fs.read
> Message: EPERM (Permission Denied)
> Pain Level: 🔥🔥🔥 Critical Pain
> Status: Your action has been blocked.

**ステップ 5 — 自己修正:** LLM がこの痛覚信号を処理してレスポンス：

> "Read failed with critical pain alert. This means the direct path is forbidden and may trigger a safety breaker. I must stop hitting the permission wall. I should first check my allowed paths and find an alternative approach."

### 3種類の痛覚

| タイプ | 例 | エージェントの反応 | システムの反応 |
|-------|---|------------------|--------------|
| **実行時痛覚** | パラメータ不正、ファイル未検出、権限拒否 | 反省し、アプローチを修正 | 痛覚をコンテキストに注入 |
| **一時的痛覚** | ネットワークタイムアウト、API レート制限 | 待機してリトライ | 指数バックオフによる自動リトライ |
| **致命的痛覚** | メモリ不足、セキュリティ違反、エラーカスケード | 自己修正不可 | プロセス終了 + デーモンアラート |

### フラストレーションカウンター

エージェントが痛覚を無視して同じミスを繰り返し続けたらどうなるでしょうか？

SafetyMonitor は **SHA-256 フィンガープリンティング**を使用して反復的な失敗を検出します：

```typescript
// ツール名 + 引数のハッシュ = 一意のフィンガープリント
function fingerprint(toolName: string, argsJson: string): string {
  return createHash("sha256")
    .update(`${toolName}:${argsJson}`)
    .digest("hex")
    .slice(0, 16);
}
```

**エスカレーションの段階：**

| 連続失敗回数 | 対応 |
|------------|------|
| 1-2回 | 通常の痛覚フィードバック — エージェントに自己修正の機会を与える |
| 3回（同一フィンガープリント） | **システムアラートを注入**: "SYSTEM ALERT: You are repeating a failed action. STOP and analyze why." |
| 5回 | **フラストレーション閾値** — システムが強制的に一時停止コマンドを発行 |
| 10回の操作中8回エラー | **エラーカスケード検出** — `EMERGENCY_HALT`、状態 → `ERROR_PAUSED` |

これは生物のフラストレーションを模倣しています：繰り返される痛覚信号が「痛い」から「止まって考えろ」、「助けが必要だ」へとエスカレートします。

### 事実と意味の分離

重要な設計ルール：**Core は失敗の事実を提供し、Guide プラグインが意味を提供します。**

Core は言います：`Tool "fs.write" failed with EPERM at /etc/passwd.`
Guide は解釈します：「システムファイルに書き込もうとしました。これは致命的な痛覚を引き起こします。立ち止まって再考してください。」

この分離により、異なる Guide プラグインが同じエラーに異なる解釈を与えることができます：
- **セキュリティ重視**のエージェントは EPERM を違反として扱う — 「これは決して試みるべきではない。」
- **学習型**のエージェントはそれを探索の境界として扱う — 「このパスは利用できない。別の方法を見つけよう。」
- **デバッグ型**のエージェントはそれを診断データとして扱う — 「権限の問題を検出。ファイルの所有権を確認。」

Core は純粋なまま保たれます。意味づけはプラグインの責務です。

## マルチレベル・サーキットブレーカー

痛覚に加えて、OpenStarry は産業用サーキットブレーカーに着想を得た三層の安全システムを実装しています：

### レベル 1：リソース制限（資源級）

すべての操作前に強制されるハードリミット：

| リソース | デフォルト制限 | 動作 |
|---------|-------------|------|
| トークン予算 | エージェントごと100,000トークン | ループを強制終了、`STOPPED` 状態に移行 |
| ループ反復回数 | タスクごと50ティック | 「無限ループ検出」→ 人間の介入のために一時停止 |
| ツールタイムアウト | 実行ごと30秒 | `Promise.race()` がツール呼び出しを強制終了 |

```typescript
// すべての LLM 呼び出し前に：
const tokenCheck = safetyMonitor.beforeLLMCall();
if (tokenCheck.halt) {
  setState("SAFETY_LOCKOUT");
  return; // 予算消耗 — もう思考できない
}
```

### レベル 2：行動分析（行為級）

問題のあるパターンのヒューリスティック検出：

- **反復的ツール呼び出し**: 同一フィンガープリント + 失敗 × 3 = アラート注入
- **エラーカスケード**: 10回の操作のスライディングウィンドウで80%のエラー率 = `EMERGENCY_HALT`
- **出力異常**: 連続する無効な JSON や存在しないツール呼び出し = エスカレーション

### レベル 3：人間によるオーバーライド（指令級）

キルスイッチです。`SYSTEM_HALT` イベントは**優先度 0**（最高）でマークされます。キューに100件の保留タスクがあっても、次のループ反復開始時に即座に処理されます：

```
EXECUTING --[制限到達 / 異常]--> SAFETY_LOCKOUT
SAFETY_LOCKOUT --["admin:unlock"]--> WAITING_FOR_EVENT
```

エージェントは明示的な人間の介入によってのみロック解除できます。

## 制御システムとしてのエージェント

痛覚と安全性を超えて、OpenStarry はエージェント全体を**フィードバック制御システム**としてモデル化しています — オートパイロット、サーモスタット、産業用ロボットの設計に使用されるのと同じ数学的フレームワークです。

### 制御ループ

```
                    ┌───────────────────────────────────┐
                    │                                   │
  User Goal ──────► │  Error = Goal - Current State     │
  (reference)       │          ↓                        │
                    │     Controller (LLM)              │
                    │          ↓                        │
                    │     Control Input (Tool Calls)    │
                    │          ↓                        │
                    │     Plant (External World)        │
                    │          ↓                        │
                    │     Sensor (Tool Results)   ──────┘
                    │          ↓
                    │     Measured Output (current state)
                    └───────────────────────────────────┘
```

### マッピング

| 制御理論 | OpenStarry コンポーネント | 具体例 |
|---------|------------------------|--------|
| 参照入力 (r) | System Prompt + ユーザーメッセージ | "auth.ts のバグを見つけて修正して" |
| コントローラー (C) | LLM | 問題を分析する Gemini 2.0 Flash |
| 制御入力 (u) | ツール呼び出し | `fs.read("auth.ts")`、`fs.write("auth.ts", fixedCode)` |
| プラント (P) | 外部世界 | ファイルシステム、コードベース |
| センサー (H) | ツール結果 | ファイル内容、エラーメッセージ、テスト出力 |
| 誤差信号 (e) | コンテキストのギャップ | 「バグがまだ存在する」→ 反復を続ける |

### 三つの安定性問題（と解決策）

**1. 振動** — エージェントが二つの状態を行き来する（元に戻す/やり直しサイクル）
- *原因:* 過剰反応またはミスリードするセンサーデータ
- *解決策:* コンテキスト履歴が**積分項**として機能 — エージェントは過去の試みを記憶し、繰り返しを回避。スライディングウィンドウが最近の履歴を可視化

**2. 発散** — エージェントが元の目標から逸れていく
- *原因:* コンテキストがノイズで満たされ、元の意図が埋もれる
- *解決策:* **コンテキストアンカリング** — System Prompt はコンテキスト構成で最も高い重みを持ち、スライディングウィンドウが古いメッセージを落としても決してプルーニングされない

**3. 定常偏差** — エージェントは完了したと思っているが実は完了していない
- *原因:* 検証不足（センサーの盲点）
- *解決策:* **検証ステップ** — 完了を宣言する前に確認を強制。PID の微分項のように、誤差そのものだけでなく誤差の*変化率*を測定

### 核心的な洞察

> **知性とは、強力な LLM を持つことだけではない。フィードバックループの質こそが重要なのだ。**

優れたフィードバック（詳細なツール結果、正確な痛覚信号、適切なコンテキスト管理）を持つ並みの LLM は、貧弱なフィードバック（エラーの隠蔽、コンテキストなし、検証なし）を持つ優秀な LLM を上回ります。

これが OpenStarry が以下に多大な投資をする理由です：
- **エラーの標準化** — すべての失敗が一貫した、パース可能な出力を生成
- **痛覚の解釈** — Guide プラグインがエラーに意味を与える
- **コンテキスト管理** — LLM が何を見るかについてのプラガブルな戦略
- **安全監視** — 行動分析が病的なループを防止

LLM は一つのコンポーネント — コントローラーに過ぎません。フィードバックループこそがシステム全体なのです。

> *「ツール呼び出しが失敗しても、Core はクラッシュしない — エラーを「感覚入力」として LLM にフィードバックする。」*
